<!DOCTYPE html><html lang="zh-CN" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="day-prompt" content="天前"><meta name="hour-prompt" content="小时前"><meta name="minute-prompt" content="分钟前"><meta name="justnow-prompt" content="刚刚"><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="机器学习之线性回归笔记" /><meta property="og:locale" content="zh_CN" /><meta name="description" content="环境准备" /><meta property="og:description" content="环境准备" /><link rel="canonical" href="https://chouzz.github.io/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%AC%94%E8%AE%B0/" /><meta property="og:url" content="https://chouzz.github.io/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%AC%94%E8%AE%B0/" /><meta property="og:site_name" content="Chouzz’s blog" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2020-01-30T23:17:53+08:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="机器学习之线性回归笔记" /><meta name="twitter:site" content="@chouzz36" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-01-01T22:44:22+08:00","datePublished":"2020-01-30T23:17:53+08:00","description":"环境准备","headline":"机器学习之线性回归笔记","mainEntityOfPage":{"@type":"WebPage","@id":"https://chouzz.github.io/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%AC%94%E8%AE%B0/"},"url":"https://chouzz.github.io/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%AC%94%E8%AE%B0/"}</script><title>机器学习之线性回归笔记 | Chouzz's blog</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Chouzz's blog"><meta name="application-name" content="Chouzz's blog"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener("change", () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } } /* ModeToggle */ const toggle = new ModeToggle(); function flipMode() { if (toggle.hasMode) { if (toggle.isSysDarkPrefer) { if (toggle.isLightMode) { toggle.clearMode(); } else { toggle.setLight(); } } else { if (toggle.isDarkMode) { toggle.clearMode(); } else { toggle.setDark(); } } } else { if (toggle.isSysDarkPrefer) { toggle.setLight(); } else { toggle.setDark(); } } toggle.notify(); } /* flipMode() */ </script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end" lang="zh-CN"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="/assets/img/avatar/Avatar.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Chouzz's blog</a></div><div class="site-subtitle font-italic">个人博客</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>首页</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>分类</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>标签</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>归档</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>关于</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/chouzz" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/chouzz36" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['zhouhua25','qq.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> 首页 </a> </span> <span>机器学习之线性回归笔记</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> 文章</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="搜索..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >取消</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>机器学习之线性回归笔记</h1><div class="post-meta text-muted"><div> 作者 <em> <a href="https://twitter.com/chouzz36">chouzz</a> </em></div><div class="d-flex"><div> <span> 发表于 <em class="timeago" date="2020-01-30 23:17:53 +0800" data-toggle="tooltip" data-placement="bottom" title="2020-01-30, 23:17 +0800" >2020-01-30</em> </span> <span> 更新于 <em class="timeago" date="2022-01-01 22:44:22 +0800 " data-toggle="tooltip" data-placement="bottom" title="2022-01-01, 22:44 +0800" >2022-01-01</em> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="2244 字"> <em>12 分钟</em>阅读</span></div></div></div><div class="post-content"><h2 id="环境准备">环境准备<a href="#环境准备" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><p><strong>平台</strong>：windows10 64 位 <strong>IDE</strong>：Pycharm <strong>Python 版本</strong>：Python3.5 <strong>github 代码</strong>：<a href="https://github.com/chouzz/machine-learning/tree/master/my_lineRegression">源代码</a></p><hr /><h2 id="回归的理解">回归的理解<a href="#回归的理解" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><p>回归是由高尔顿最先在生物遗传上提出的，在线性回归中，与其说其为回归，不如说线性拟合更合适，而为了纪念高尔顿还是保留了回归这一名词 而<strong>对数几率回归（Logistic regression）</strong>解决的却是一个<strong>分类</strong>问题，其实就是 2 分类，如果需要解决多分类那么就做多次 2 分类或直接用<strong>Softmax 回归</strong>。</p><h2 id="线性回归">线性回归<a href="#线性回归" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><p>线性回归试图建立的一个线性模型以尽可能准确的预测输出标记。考虑最简单的模型，给定若干对$(x,y)$的数据，将其在坐标轴上表示如下：</p><center>![散点图](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWctYmxvZy5jc2RuLm5ldC8yMDE4MDMxNDIyMjYxOTQ1Mj93YXRlcm1hcmsvMi90ZXh0L0x5OWliRzluTG1OelpHNHVibVYwTDNGeE9UQTBNekExTVRVNS9mb250LzVhNkw1TDJUL2ZvbnRzaXplLzQwMC9maWxsL0kwSkJRa0ZDTUE9PS9kaXNzb2x2ZS83MA?x-oss-process=image/format,png) 线性回归就是要寻找一条直线来使得这些所有的点都尽量符合直线上的点，其中尽量符合指的就是使损失最小，在这里以点到直线的距离的平方来作为‘损失’，使用线性回归可以来预测数据，这在机器学习里面是一个非常重要的概念——预测，不管是什么模型，最后做出来都是需要用来预测数据，来判断这个模型到底实不实用，线性回归就是这些模型中最简单的一种模型。 <center>![线性回归图](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWctYmxvZy5jc2RuLm5ldC8yMDE4MDMxNDIyMjY1MDM4Mj93YXRlcm1hcmsvMi90ZXh0L0x5OWliRzluTG1OelpHNHVibVYwTDNGeE9UQTBNekExTVRVNS9mb250LzVhNkw1TDJUL2ZvbnRzaXplLzQwMC9maWxsL0kwSkJRa0ZDTUE9PS9kaXNzb2x2ZS83MA?x-oss-process=image/format,png) ## 使用最大似然解释最小二乘 ### 基本形式 首先对于线性回归，所求得就是一条直线，设其方程为： $$y^{(i)}=\theta^Tx^{(i)}+\varepsilon^{(i)}$$ 其中$\theta$和$\varepsilon$为这条直线的斜率和截距，$x,y$分别为图上的一系列散点，用极大似然法估计时，我们认为$\varepsilon$符合正太分布，且期望为 0，那么根据大学的知识可以得到$\varepsilon$的概率为： $$p(\varepsilon^{(i)})=\frac{1}{s\sqrt{2\pi\sigma}}exp(-\frac{(\varepsilon^{(i)})^2}{2\sigma^2})$$ 把直线方程移项带入上式得到在$\theta$参数下，已知$x$的情况下$y$的概率密度函数为： $$p(y^{(i)}|x^{(i)};\theta)=\frac{1}{\sqrt{2\pi\sigma}}exp(-\frac{(y^{(i)}-\theta^Tx^{(i)})^2}{2\sigma^2})$$ 这里的概率密度函数为条件概率密度函数，直接求解是无法解出来的，假设样本之间是独立的，那么就得到： \begin{aligned} L(\theta)&amp;=\coprod*{i=1}^m p(y^{(i)}|x^{(i)};\theta)\\&amp;=\coprod*{i=1}^m\frac{1}{\sqrt{2\pi\sigma}}exp(-\frac{(y^{(i)}-\theta^Tx^{(i)})^2}{2\sigma^2}) \end{aligned} ### 高斯的对数似然与最小二乘 这里用的是对数似然，即需要对$L(\theta)$取对数，则可以化简得到如下方程： \begin{aligned} \ell(\theta)&amp;=\log{L(\theta)}\\&amp;=\log{\coprod*{i=1}^m\frac{1}{\sqrt{2\pi\sigma}}exp(-\frac{(y^{(i)}-\theta^Tx^{(i)})^2}{2\sigma^2})}\\&amp;=\sum*{i=1}^m \log{\frac{1}{\sqrt{2\pi\sigma}}exp(-\frac{(y^{(i)}-\theta^Tx^{(i)})^2}{2\sigma^2})}\\&amp;=m\log{\frac{1}{\sqrt{2\pi\sigma}}}-\frac{1}{\sigma^2}\cdot\frac{1}{2}\sum*{i=1}^m(y^{(i)}-theta^Tx^{(i)}) \end{aligned} 现在，需要求$L(\theta)$为最大值时$\theta$的值，前面一项为常数，可以省略掉，只保留后方一项得到函数： $$J(\theta)=\frac{1}{2}\sum*{i=1}^m(y^{(i)}-\theta^Tx^{(i)})$$ 即求$J(\theta)$的最小值，括号里的一项就是预测值和实际值之间的差，这个就成为目标函数或成为损失函数，这其实就是最小二乘估计，整个推导过程其实就是利用高斯分布推导最小二乘。 ### 向量表示下的求解 设有$M$个$N$维样本组成矩阵$X$，即$X$的行对应每个样本，$X$的列对应样本的维度，**目标函数**就可以表示为： $$J(\theta)=\frac{1}{2}\sum_{i=1}^m (h_\theta(x^{(i)})-y^{(i)})^2=\frac{1}{2}(X\theta-y)^T(X\theta-y)$$ 即现在要求出$J(\theta)$最小值时$\theta$的值，对目标函数求导，令其等于$0$，求出$\theta$的值。 \begin{aligned} \nabla*\theta J(\theta) &amp;= \frac{1}{2}\sum*{i=1}^m(h*\theta x^{(i)}-y^{(i)})^2\\&amp;=\nabla*\theta \left\{ \frac{1}{2} (\theta^TX^TX\theta-]theta^TX^Ty-y^TX\theta+h^Ty)\right\}\\&amp;=\frac{1}{2}(2X^TX\theta-X^Ty-(y^TX)^T)\\&amp;=X^TX\theta-x^Ty \end{aligned} 得到最后的结果如下： $$\theta=(X^TX)^{-1}X^Ty$$ ### L2 正则化($\ell2-norm$) 而在现实中当特征比样本点更多时，矩阵$X$不是满秩矩阵， $X^TX$不一定可逆，通常引入**正则化(egularization)**项，其实质是为了**防止过拟合**, $$ \frac{1}{2}\sum*{i=1}^m(h*\theta x^{(i)}-y^{(i)})^2+\lambda\sum\_{j=1}^n\theta_j ^2$$ 称为**$L2$正则($\ell2-norm$)**，那么加了$L2$正则的最小二乘称为**岭回归**，求解可得$\theta$为： $$\theta=(X^TX+\lambda I)^{-1}X^Ty$$ ### L1 正则化($\ell1-norm$) 既然有 L2 正则化，那么也必然有**L1 正则化($\ell1-norm$)**，将目标函数正则项中$\theta$的平方替换为$\theta$的绝对值，那么就叫 L1 正则，即**LASSO**。 $$ \frac{1}{2}\sum*{i=1}^m(h*\theta x^{(i)}-y^{(i)})^2+\lambda\sum\_{j=1}^n|\theta_j| $$ ### lastic Net 结合 l1 和 l2 正则，即为 Elastic Net: $$ \frac{1}{2}\sum*{i=1}^m(h*\theta x^{(i)}-y^{(i)})^2+\lambda(\rho\cdot\sum*{j=1}^n|\theta_j| +(1-\rho)\cdot\sum*{j=1}^n\theta_j ^2)$$ ### L1 和 L2 正则的区别 使用绝对值取代平方和，在$\lambda$最够大时，高阶的情况下高阶项的系数会缩减到 0 ## 梯度下降法 求出目标函数了，就要根据目标函数来求的这条直线，这里常用的一种方法就是梯度下降法，梯度下降法的公式如下： $$\theta=\theta-\alpha\cdot\frac{\partial J(\theta)}{\partial\theta}$$ 其中$\alpha$表示学习率，$\theta$为参数，具体做法就是初始化$\theta$，然后沿着负梯度方向迭代，不断更新$\theta$使就$J(\theta)$最小。 ## 程序分析 ```python import numpy as np import matplotlib.pyplot as plt np.random.seed(0) x = np.linspace(0, 6, 11) + np.random.randn(11) x = np.sort(x) y = x ** 2 + 2 + np.random.randn(11) ``` 首先生成随机点 x，y，随机生成 11 个点，这 11 个点是根据 y=x2+2 这条曲线上生成的。 ```python def optimizer(): w = 0 b = 0 for i in range(1000): w, b = compute_gradient(w, b, 0.02) # if i % 50 == 0: # plt.plot(x, x * w + b, 'b-') # plt.pause(0.5) y_pre = x * w + b print(w, b) return y_pre ``` 这个函数是执行梯度下降法 1000 次，以此来找到最优的 w，b，每执行一次，都将新的 w，b 带入梯度中来求，最后求得最终的 w，b，然后可以得到最终拟合的直线，即 y_pre. ```pyhon def compute_gradient(m_current, b_current, learning_rate): N = len(x) # 数据的长度 m_gradient = 0.0 b_gradient = 0.0 for i in range(N): m_gradient += -(2 / N) * x[i] * (y[i] - (m_current * x[i] + b_current)) b_gradient += -(2 / N) * (y[i] - (m_current * x[i] + b_current)) new_m = m_current - (learning_rate * m_gradient) new_b = b_current - (learning_rate * b_gradient) return new_m, new_b ``` 在 compute_gradient 函数中，主要是返回每次计算的$w，b$以及 $\frac{\partial J(\theta)}{\partial\theta}$，上面函数中 for 循环就是所求的偏导数，返回值是计算一次梯度下降时的$w，b$。 ```python plt.plot(x, y, 'ro') plt.plot(x, optimizer(), 'b-') #optimizer() plt.show() ``` 在多次计算后，再将散点图最终求得的直线图画出来即可。 ## 分析 sklearn 线性回归的官方例程 官方网站为：[Linear Regression Example](http://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html#sphx-glr-auto-examples-linear-model-plot-ols-py) ### 官方例程分析 ```python import matplotlib.pyplot as plt import numpy as np from sklearn import datasets, linear_model from sklearn.metrics import mean_squared_error, r2_score ``` 导入库 ``` diabetes = datasets.load_diabetes() # 导出数据集 ``` 导出数据集，其中 diabetes 是`sklearn.datasets.base.Bunch`类型，该类型和 Python 内置的字典类型相似 ``` diabetes_X = diabetes.data[:, np.newaxis, 2] # 分割数据集 ``` 这个用法为 sklearn 中的用法，`datasets.data`为`dataset`对象中的`data`属性，而`data`属性对应的数据为一个二维数组，故`[:, np.newaxis,2]`为取 data 中的所有行，增加一个维度，第三列,故`diabetes_X`为一个二维数组,如下： ``` {'data': array([[ 0.03807591, 0.05068012, 0.06169621, ..., -0.00259226, 0.01990842, -0.01764613], [-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338, -0.06832974, -0.09220405], [ 0.08529891, 0.05068012, 0.04445121, ..., -0.00259226, 0.00286377, -0.02593034], ..., [ 0.04170844, 0.05068012, -0.01590626, ..., -0.01107952, -0.04687948, 0.01549073], [-0.04547248, -0.04464164, 0.03906215, ..., 0.02655962, 0.04452837, -0.02593034], [-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338, -0.00421986, 0.00306441]]), ``` 上面得到的 diabetes_X 的 shape 为(442, 1)，再将其分为训练集和测试集 ``` diabetes_X_train = diabetes_X[:-20] diabetes_X_test = diabetes_X[-20:] ``` 该句中前 0 个到倒数第 20 个分为训练集，倒数 20 个数据为测试集。 ``` diabetes_y_train = diabetes.target[:-20] diabetes_y_test = diabetes.target[-20:] ``` 同理，将 diabetes 中的 target 属性也这样划分。 ``` regr = linear_model.LinearRegression() regr.fit(diabetes_X_train, diabetes_y_train) diabetes_y_pred = regr.predict(diabetes_X_test) ``` 然后创建一个线性模型的对象，并用训练集来 fit，最后得到预测的数据 ``` # The coefficients print('Coefficients: \n', regr.coef_) # The mean squared error print("Mean squared error: %.2f" % mean_squared_error(diabetes_y_test, diabetes_y_pred)) # Explained variance score: 1 is perfect prediction print('Variance score: %.2f' % r2_score(diabetes_y_test, diabetes_y_pred)) ``` 打印出相关系数和均方误差以及差异分数 这里相关系数为$R$，回归系数为$R^2$,而回归系数 $$R^2=\frac{SSReg}{SST}=1-\frac{SSE}{SST}$$ 其中$SSReg$为回归平方和（sum of squares for regression），也叫做模型平方和，，SSE 为残差平方（sum of squares for error），SST 为总平方和（SSReg+SSE），其中各公式如下： $$SST=\sum_{i=1}^n(y_i-\bar{y})^2$$ $$SSReg=\sum_{i}(\hat{y_i}-\bar{y})^2$$ $$SSE=\sum_{i}(y_i-\hat{y})^2$$ 故在本次实验中相关系数$R$即为： $$R=\frac{\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})}{\sqrt{\sum_{i=1}^n(x_i-\bar{x})^2\sum_{i=1}^n(y_i-\bar{y})^2}}$$ $\hat{y_i}$表示的为回归直线中$y$的值，$\bar{y}$表示$y$的平均值.最后结果如下： <center>![官方例程结果](https://img-blog.csdn.net/20180328112825821?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxOTA0MzA1MTU5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70) ## 7.2 使用sklearn方法训练自己生成的数据 代码如下： ```python import matplotlib.pyplot as plt import numpy as np from sklearn import datasets, linear_model from sklearn.metrics import mean_squared_error, r2_score np.random.seed(0) x = np.linspace(0, 6, 11) + np.random.randn(11) x = np.sort(x) y = x \*\* 2 + 2 + np.random.randn(11) x=x[:,np.newaxis] print(x) regr = linear_model.LinearRegression() regr.fit(x,y) y_pre = regr.predict(x) plt.scatter(x,y) plt.plot(x,y_pre) plt.show() ``` 预测结果： ![sklaern预测生成数据结果](https://img-blog.csdn.net/20180328113152895?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxOTA0MzA1MTU5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70) 可以看到，使用sklearn的预测结果和使用梯度下降法的线性回归结果是一模一样的。 # 8 参考书目 - 机器学习实战 - 机器学习 周志华 - [线性回归理解（附纯python实现）](http://blog.csdn.net/sxf1061926959/article/details/66976356?locationNum=9&amp;fps=1) - [sklaern官网例程](http://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html#sphx-glr-auto-examples-linear-model-plot-ols-py) ``` </center></center></center></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/'>机器学习</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/" class="post-tag no-text-decoration" >线性回归</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> 本文由作者按照 <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> 进行授权</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">分享</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=机器学习之线性回归笔记 - Chouzz's blog&url=https://chouzz.github.io/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%AC%94%E8%AE%B0/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=机器学习之线性回归笔记 - Chouzz's blog&u=https://chouzz.github.io/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%AC%94%E8%AE%B0/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=机器学习之线性回归笔记 - Chouzz's blog&url=https://chouzz.github.io/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%AC%94%E8%AE%B0/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="分享链接" title-succeed="链接已复制！"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">最近更新</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/%E7%99%BD%E6%97%A5%E6%A2%A6%E6%83%B3%E5%AE%B6-%E8%A7%82%E5%90%8E%E6%84%9F/">《白日梦想家》观后感</a><li><a href="/posts/LeetCode455-%E5%88%86%E5%8F%91%E9%A5%BC%E5%B9%B2/">LeetCode455 分发饼干</a><li><a href="/posts/%E4%B8%A4%E6%95%B0%E4%B9%8B%E5%92%8CII-%E8%BE%93%E5%85%A5%E6%9C%89%E5%BA%8F%E6%95%B0%E7%BB%84/">两数之和II-输入有序数组</a><li><a href="/posts/python%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">python学习笔记</a><li><a href="/posts/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/">Cpp设计模式之工厂模式</a></ul></div><div id="access-tags"><div class="panel-heading">热门标签</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/%E9%93%BE%E8%A1%A8/">链表</a> <a class="post-tag" href="/tags/%E6%A0%88/">栈</a> <a class="post-tag" href="/tags/%E6%95%B0%E7%BB%84/">数组</a> <a class="post-tag" href="/tags/%E9%98%9F%E5%88%97/">队列</a> <a class="post-tag" href="/tags/python/">python</a> <a class="post-tag" href="/tags/resnet/">ResNet</a> <a class="post-tag" href="/tags/turtlebot/">turtlebot</a> <a class="post-tag" href="/tags/%E4%B8%9C%E9%87%8E%E5%9C%AD%E5%90%BE/">东野圭吾</a> <a class="post-tag" href="/tags/%E5%86%B3%E7%AD%96%E6%A0%91/">决策树</a> <a class="post-tag" href="/tags/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/">单例模式</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">文章内容</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="tail-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>相关文章</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA%E7%8E%AF%E5%A2%83%E8%AE%B0%E5%BD%95/"><div class="card-body"> <em class="timeago small" date="2020-01-30 21:35:32 +0800" >2020-01-30</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>深度学习服务器搭建环境记录</h3><div class="text-muted small"><p> 下载 anaconda anaconda 的安装比较简单，参考官方文档的安装即可，可以通过 Linux 下 wget 命令下载 anaconda 安装包，官网安装包下载比较慢，推荐使用清华开源软件镜像站下载，注意需要下载的版本要和 python 的版本对应，我想使用 python3.6，故而下载的是 anaconda5.2.0,当然，也可以下载最新的 anaconda 版本，再通过创建虚拟...</p></div></div></a></div><div class="card"> <a href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%86%B3%E7%AD%96%E6%A0%91%E7%AC%94%E8%AE%B0/"><div class="card-body"> <em class="timeago small" date="2020-01-30 22:50:13 +0800" >2020-01-30</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>机器学习之决策树笔记</h3><div class="text-muted small"><p> 环境准备 平台：windows10 64 位 IDE：Pycharm Python 版本：Python 3.5 github 代码：源代码 my_DecisionTree.py 决策树 决策树(decision tree)是一种常见的机器学习方法，其实在生活中我们已经用到了决策树相关的知识，比如说，女生相亲时的想法就是决策树的一种体现： 那么对于一般女生来说，首选的就是看对方...</p></div></div></a></div><div class="card"> <a href="/posts/%E7%99%BD%E5%A4%9C%E8%A1%8C%E8%AF%BB%E5%90%8E%E6%84%9F/"><div class="card-body"> <em class="timeago small" date="2022-03-04 21:50:00 +0800" >2022-03-04</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>白夜行读后感</h3><div class="text-muted small"><p> 文章先开始介绍了一宗谋杀案，桐原良介被谋杀了，而他老婆以前是做妓女的，和他的店铺的店长有点可疑，但是又没有什么特别的证据，他有一个儿子桐原亮司，然后警方又找到了他临死前去的地方，也就是西本文代家，西本文代有个女儿，自己也是那种高冷美人，老公七年前就死了，家里比较平穷，有一个很可爱很聪明的女儿，西本雪慧。 第二章讲的是秋吉雄一是个玩摄影的穷小子，他被派去偷拍雪穗，他有一个好基友菊池文彦，然后...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%86%B3%E7%AD%96%E6%A0%91%E7%AC%94%E8%AE%B0/" class="btn btn-outline-primary" prompt="上一篇"><p>机器学习之决策树笔记</p></a> <a href="/posts/LeetCode86-%E5%88%86%E5%89%B2%E9%93%BE%E8%A1%A8/" class="btn btn-outline-primary" prompt="下一篇"><p>LeetCode86 分割链表</p></a></div><div id="disqus_thread" class="pt-2 pb-2"><p class="text-center text-muted small"> Comments powered by <a href="https://disqus.com/">Disqus</a>.</p></div><script type="text/javascript"> var disqus_config = function () { this.page.url = 'https://chouzz.github.io/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%AC%94%E8%AE%B0/'; this.page.identifier = '/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%AC%94%E8%AE%B0/'; }; /* Lazy loading */ var disqus_observer = new IntersectionObserver(function (entries) { if(entries[0].isIntersecting) { (function () { var d = document, s = d.createElement('script'); s.src = 'https://github-aqg6kwj8f1.disqus.com/embed.js'; s.setAttribute('data-timestamp', +new Date()); (d.head || d.body).appendChild(s); })(); disqus_observer.disconnect(); } }, { threshold: [0] }); disqus_observer.observe(document.querySelector('#disqus_thread')); /* Auto switch theme */ function reloadDisqus() { /* Disqus hasn't been loaded */ if (typeof DISQUS === "undefined") { return; } if (document.readyState == 'complete') { DISQUS.reset({ reload: true, config: disqus_config }); } } const modeToggle = document.querySelector(".mode-toggle"); if (typeof modeToggle !== "undefined") { /* modeToggle.addEventListener('click', reloadDisqus); // not pretty for 'color-scheme' */ window.matchMedia('(prefers-color-scheme: dark)').addEventListener('change', reloadDisqus); } </script></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center text-muted"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://twitter.com/chouzz36">chouzz</a>. <span data-toggle="tooltip" data-placement="top" title="除非另有说明，本网站上的博客文章均由作者按照知识共享署名 4.0 国际 (CC BY 4.0) 许可协议进行授权。">保留部分权利。</span></p></div><div class="footer-right"><p class="mb-0"> 本站由 <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> 生成，采用 <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> 主题。</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">热门标签</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/%E9%93%BE%E8%A1%A8/">链表</a> <a class="post-tag" href="/tags/%E6%A0%88/">栈</a> <a class="post-tag" href="/tags/%E6%95%B0%E7%BB%84/">数组</a> <a class="post-tag" href="/tags/%E9%98%9F%E5%88%97/">队列</a> <a class="post-tag" href="/tags/python/">python</a> <a class="post-tag" href="/tags/resnet/">ResNet</a> <a class="post-tag" href="/tags/turtlebot/">turtlebot</a> <a class="post-tag" href="/tags/%E4%B8%9C%E9%87%8E%E5%9C%AD%E5%90%BE/">东野圭吾</a> <a class="post-tag" href="/tags/%E5%86%B3%E7%AD%96%E6%A0%91/">决策树</a> <a class="post-tag" href="/tags/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/">单例模式</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">搜索结果为空</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-JDPSEB5E1H"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-JDPSEB5E1H'); }); </script>
